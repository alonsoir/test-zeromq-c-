## ‚úÖ Actualizaci√≥n del Prompt - Recordatorio Documentos

Tienes raz√≥n, necesito a√±adir esa secci√≥n. Aqu√≠ est√° el **prompt actualizado con recordatorio expl√≠cito**:

---

# PROMPT DE CONTINUIDAD - D√çA 33 (04 Enero 2026)

## üìö DOCUMENTOS NECESARIOS PARA ESTA SESI√ìN

```
Day 33 (HOY):
  ‚ùå NO pasar FAISS_ANTI_CURSE_DESIGN.md
  ‚úÖ Solo este prompt de continuidad
  
Raz√≥n: Day 33-34 son creaci√≥n de modelos ONNX.
       No implementamos estrategias anti-curse todav√≠a.
       El resumen abajo es suficiente.

RECORDATORIO PARA D√çAS FUTUROS:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Day 35 (DimensionalityReducer):                    ‚îÇ
‚îÇ   ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md              ‚îÇ
‚îÇ   Raz√≥n: Implementar Estrategia #2 (PCA)          ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ Day 36 (√çndices Separados + Selective):           ‚îÇ
‚îÇ   ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md              ‚îÇ
‚îÇ   Raz√≥n: Implementar Estrategias #1 y #3          ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ Day 38-40 (Advanced Strategies):                   ‚îÇ
‚îÇ   ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md              ‚îÇ
‚îÇ   Raz√≥n: Temporal Tiers, Re-ranking, etc.         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Archivo: /vagrant/docs/FAISS_ANTI_CURSE_DESIGN.md
Tama√±o: ~500 l√≠neas (12K tokens aprox)
```

---

## üìã CONTEXTO D√çA 32 (03 Enero 2026) - COMPLETADO ‚úÖ

### ‚úÖ ONNX Runtime Test - Infrastructure Complete

**Day 32 - ONNX Integration:**
- ‚úÖ create_dummy_model_lite.py: 10‚Üí32-d embedder (sin PyTorch)
- ‚úÖ test_onnx_basic.cpp: Load + inference test (ALL TESTS PASSED ‚úÖ)
- ‚úÖ Makefile: Auto-genera modelo antes de test (reproducible)
- ‚úÖ .gitignore: *.onnx (no binarios en git)
- ‚úÖ CMakeLists.txt: test_onnx_basic target habilitado

**Infrastructure Status (Day 32 Complete):**
```
‚úÖ FAISS v1.8.0 - WORKING
   ‚îú‚îÄ test_faiss_basic PASSING
   ‚îú‚îÄ CV computation validated
   ‚îî‚îÄ Auto-detection working

‚úÖ ONNX Runtime v1.17.1 - WORKING
   ‚îú‚îÄ test_onnx_basic PASSING
   ‚îú‚îÄ Inference pipeline validated
   ‚îî‚îÄ Auto-detection working

‚úÖ Build System - ROBUST
   ‚îú‚îÄ CMakeLists.txt: C++20, auto-detect
   ‚îú‚îÄ Makefile: test-faiss, test-onnx, test-all
   ‚îî‚îÄ All targets working

‚úÖ Strategic Design - PEER REVIEWED
   ‚îú‚îÄ FAISS_ANTI_CURSE_DESIGN.md v2.0
   ‚îú‚îÄ 11 estrategias definidas
   ‚îú‚îÄ Peer review: 4 AI systems
   ‚îî‚îÄ L√≠mites emp√≠ricamente validados
```

**Test Results (Day 32):**
```
make test-faiss  ‚Üí ALL TESTS PASSED ‚úÖ
make test-onnx   ‚Üí ALL TESTS PASSED ‚úÖ
make test-all    ‚Üí BOTH PASSING ‚úÖ
make verify-libs ‚Üí FAISS + ONNX OK ‚úÖ
```

**Git Status:**
```
Rama: feature/faiss-ingestion-phase2a
√öltimo commit: "Day 32 complete - ONNX Runtime test passing"
Archivos a√±adidos:
  - rag/tests/create_dummy_model_lite.py
  - rag/tests/test_onnx_basic.cpp
  - rag/Makefile (updated)
  - rag/CMakeLists.txt (updated)
  - .gitignore (*.onnx)
```

---

## üî¨ RESUMEN ESTRATEGIAS ANTI-CURSE (Para Referencia Day 33-34)

**Estrategias que implementaremos Days 35+:**

### üî¥ CR√çTICAS - Phase 2A (Days 35-38)

**1. √çndices Separados por Clase** (Day 36)
- Benign index vs Malicious index
- 10x mejora para Attack embedder
- Evita saturaci√≥n cross-class

**2. Dimensionality Reduction Post-Embedding** (Day 35)
- **CR√çTICO**: Usar faiss::PCAMatrix (NO Eigen manual)
- 512‚Üí128 (preserva 96.8% varianza), 384‚Üí96, 256‚Üí64
- 4x mejora en l√≠mites
- **Necesitaremos FAISS_ANTI_CURSE_DESIGN.md en Day 35**

**3. Selective Embedding** (Day 36)
- Malicious: 100% embedded
- Benign: 10% sampling (hash determinista)
- 10x mejora para clase benign

### üü° IMPORTANTES - Phase 2B (Days 38-40)

**4. Temporal Tiers** (Day 39)
- Hot (7 d√≠as): ~700 eventos, CV > 0.3
- Warm (30 d√≠as): IVF, CV > 0.2
- Cold (30+ d√≠as): IVF+PQ, compressed

**5. Metadata-First Search** (Day 38)
- Pre-filter con SQL/etcd
- FAISS solo para refinamiento

**6. Quantization** (Day 40)
- float32 ‚Üí int8 (4x compresi√≥n)
- <1% p√©rdida precisi√≥n

### üîµ AVANZADAS - Qwen Contributions

**9. IVF Attack-Aware** (Day 39)
**10. Two-Stage Re-ranking** (Day 38)
**11. Cold Start Strategy** (Day 35)

**L√≠mites Emp√≠ricamente Validados:**
```
Chronos (512-d ‚Üí 128-d): 180K eventos (CV = 0.20)
SBERT (384-d ‚Üí 96-d):    450K eventos (CV = 0.20)
Attack (256-d ‚Üí 64-d):   85K benign (CV = 0.20)
```

---

## üéØ ESTADO ACTUAL - D√çA 33 INICIO

### ‚úÖ Completado Hasta Ahora

**Phase 2A Infrastructure (Days 31-32):**
- ‚úÖ FAISS v1.8.0 instalado, testeado, working
- ‚úÖ ONNX Runtime v1.17.1 instalado, testeado, working
- ‚úÖ Build system configurado (C++20, auto-detection)
- ‚úÖ Tests pasando (test_faiss_basic, test_onnx_basic)
- ‚úÖ Anti-curse design completado (v2.0, peer-reviewed)

**Datos Disponibles:**
- ‚úÖ 32,957 eventos RAG (JSONL format)
- ‚úÖ 43,526 artifacts Protobuf
- ‚úÖ 43,526 artifacts JSON
- ‚ùå NO tenemos embeddings pre-computados (.npy)
- ‚ùå NO tenemos modelos embedder entrenados todav√≠a

### üöß Pendiente - Week 5

**Days 33-34: Real Embedder Models**
- Export/crear modelos ONNX reales
- Chronos (time series): 83 features ‚Üí 512-d
- SBERT (semantic): 83 features ‚Üí 384-d
- Attack (custom): 83 features ‚Üí 256-d
- Test inference con estructura real

**Days 35-40: Implementation**
- DimensionalityReducer (faiss::PCAMatrix) ‚Üê **PASAR DESIGN DOC**
- AttackIndexManager (√≠ndices separados) ‚Üê **PASAR DESIGN DOC**
- SelectiveEmbedder (sampling) ‚Üê **PASAR DESIGN DOC**
- ChunkCoordinator integration
- End-to-end pipeline

---

## üöÄ PLAN D√çA 33 - REAL EMBEDDER MODELS (Parte 1)

### üéØ Objetivo del D√≠a

**Focus**: Crear/exportar modelos ONNX reales para los 3 embedders, preparar para ingestion.

**Contexto Importante:**
- NO tenemos embeddings pre-computados
- NO tenemos modelos custom entrenados
- Soluci√≥n: Usar modelos base/pre-trained + adapters simples

**Timeline**: 4-6 horas total

**Status**: Infrastructure ‚úÖ ‚Üí Embedders ONNX (Day 33-34) ‚Üí DimensionalityReducer (Day 35)

---

### DESAF√çO: No Tenemos Modelos Entrenados

**Problema:**
```
Dise√±o original asume:
  1. Chronos embedder custom (entrenado)
  2. SBERT embedder custom (entrenado)  
  3. Attack embedder custom (entrenado)

Realidad:
  ‚ùå No tenemos estos modelos
  ‚ùå Entrenarlos requiere semanas + GPU
```

**Soluci√≥n Pragm√°tica (Via Appia Quality):**
```
Day 33-34: Usar modelos base + arquitectura correcta
  ‚úÖ Chronos: Modelo time-series sint√©tico (83‚Üí512-d)
  ‚úÖ SBERT: sentence-transformers base (texto‚Üí384-d)
  ‚úÖ Attack: Neural network simple (83‚Üí256-d)
  
Objetivo: Validar PIPELINE, no entrenar modelos
         (Modelos reales = future work / production)
```

---

### FASE 1: Chronos Time Series Embedder (2 horas)

**Objetivo**: Crear modelo ONNX que acepta 83 features ‚Üí 512-d embedding

**Opci√≥n A: Modelo Sint√©tico (Recommended)**

```python
# File: rag/models/create_chronos_embedder.py
#!/usr/bin/env python3
"""
Create Chronos-style time series embedder for ML Defender.

Input:  83 network traffic features (float32)
Output: 512-d time series embedding (float32)

Architecture: Simple MLP mimicking time series processing
Note: This is a PLACEHOLDER for real Chronos model training
"""

import torch
import torch.nn as nn
import onnx

class ChronosEmbedder(nn.Module):
    """
    Time series embedder: 83 features ‚Üí 512-d
    
    Architecture mimics real time series processing:
    - Input layer: 83 network features
    - Hidden layers: Capture temporal patterns
    - Output: 512-d embedding
    """
    def __init__(self, input_dim=83, hidden_dim=256, output_dim=512):
        super().__init__()
        
        self.network = nn.Sequential(
            # Layer 1: Feature extraction
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            # Layer 2: Pattern detection
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.LayerNorm(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            # Layer 3: Embedding projection
            nn.Linear(hidden_dim * 2, output_dim),
            nn.Tanh()  # Normalize to [-1, 1]
        )
    
    def forward(self, x):
        return self.network(x)

def main():
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  Creating Chronos Embedder (83‚Üí512-d) ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
    
    # Create model
    print("Step 1: Initializing Chronos architecture...")
    model = ChronosEmbedder(input_dim=83, output_dim=512)
    model.eval()
    print("  ‚úÖ Model initialized (83 ‚Üí 512-d)\n")
    
    # Dummy input for export
    print("Step 2: Creating export input...")
    dummy_input = torch.randn(1, 83)
    print(f"  ‚úÖ Input shape: {dummy_input.shape}\n")
    
    # Export to ONNX
    print("Step 3: Exporting to ONNX...")
    torch.onnx.export(
        model,
        dummy_input,
        "chronos_embedder.onnx",
        input_names=['features'],
        output_names=['embedding'],
        dynamic_axes={
            'features': {0: 'batch_size'},
            'embedding': {0: 'batch_size'}
        },
        opset_version=14,
        verbose=False
    )
    print("  ‚úÖ Exported: chronos_embedder.onnx\n")
    
    # Verify
    print("Step 4: Verifying model...")
    onnx_model = onnx.load("chronos_embedder.onnx")
    onnx.checker.check_model(onnx_model)
    print("  ‚úÖ Model verified (opset 14)\n")
    
    print("Model Information:")
    print("  Input:  features (batch, 83)")
    print("  Output: embedding (batch, 512)")
    print("  Type:   Time series embedder (MLP)")
    print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  Chronos Embedder Created ‚úÖ           ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")

if __name__ == "__main__":
    main()
```

**Ejecutar:**
```bash
cd /vagrant/rag/models
mkdir -p /vagrant/rag/models  # Si no existe
python3 create_chronos_embedder.py

# Verificar
ls -lh chronos_embedder.onnx
```

---

### FASE 2: SBERT Semantic Embedder (1.5 horas)

**Objetivo**: Crear modelo que genera embeddings sem√°nticos de features de red

**Opci√≥n: Arquitectura Simple (features ‚Üí text concept ‚Üí embedding)**

```python
# File: rag/models/create_sbert_embedder.py
#!/usr/bin/env python3
"""
Create SBERT-style semantic embedder for ML Defender.

Input:  83 network traffic features (float32)
Output: 384-d semantic embedding (float32)

Architecture: MLP that maps features to semantic space
Note: Real SBERT would use transformers, this is simplified
"""

import torch
import torch.nn as nn
import onnx

class SBERTEmbedder(nn.Module):
    """
    Semantic embedder: 83 features ‚Üí 384-d
    
    Simplified version of sentence-BERT concept
    Maps network features to semantic embedding space
    """
    def __init__(self, input_dim=83, hidden_dim=192, output_dim=384):
        super().__init__()
        
        self.network = nn.Sequential(
            # Semantic feature extraction
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),  # GELU like transformers
            
            # Semantic representation
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.LayerNorm(hidden_dim * 2),
            nn.GELU(),
            
            # Final embedding
            nn.Linear(hidden_dim * 2, output_dim),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.network(x)

def main():
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  Creating SBERT Embedder (83‚Üí384-d)   ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
    
    print("Step 1: Initializing SBERT architecture...")
    model = SBERTEmbedder(input_dim=83, output_dim=384)
    model.eval()
    print("  ‚úÖ Model initialized (83 ‚Üí 384-d)\n")
    
    print("Step 2: Creating export input...")
    dummy_input = torch.randn(1, 83)
    print(f"  ‚úÖ Input shape: {dummy_input.shape}\n")
    
    print("Step 3: Exporting to ONNX...")
    torch.onnx.export(
        model, dummy_input, "sbert_embedder.onnx",
        input_names=['features'],
        output_names=['embedding'],
        dynamic_axes={
            'features': {0: 'batch_size'},
            'embedding': {0: 'batch_size'}
        },
        opset_version=14,
        verbose=False
    )
    print("  ‚úÖ Exported: sbert_embedder.onnx\n")
    
    print("Step 4: Verifying model...")
    onnx_model = onnx.load("sbert_embedder.onnx")
    onnx.checker.check_model(onnx_model)
    print("  ‚úÖ Model verified\n")
    
    print("Model Information:")
    print("  Input:  features (batch, 83)")
    print("  Output: embedding (batch, 384)")
    print("  Type:   Semantic embedder (SBERT-style)")
    print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  SBERT Embedder Created ‚úÖ             ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")

if __name__ == "__main__":
    main()
```

---

### FASE 3: Attack Embedder (1 hora)

```python
# File: rag/models/create_attack_embedder.py
#!/usr/bin/env python3
"""
Create Attack-specific embedder for ML Defender.

Input:  83 network traffic features (float32)
Output: 256-d attack embedding (float32)

Architecture: Focused on attack pattern detection
"""

import torch
import torch.nn as nn
import onnx

class AttackEmbedder(nn.Module):
    """
    Attack embedder: 83 features ‚Üí 256-d
    
    Specialized for attack pattern detection
    Smaller dimension for class-separated indices
    """
    def __init__(self, input_dim=83, hidden_dim=128, output_dim=256):
        super().__init__()
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.ReLU(),
            
            nn.Linear(hidden_dim * 2, output_dim),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.network(x)

def main():
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  Creating Attack Embedder (83‚Üí256-d)  ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
    
    print("Step 1: Initializing Attack architecture...")
    model = AttackEmbedder(input_dim=83, output_dim=256)
    model.eval()
    print("  ‚úÖ Model initialized (83 ‚Üí 256-d)\n")
    
    print("Step 2: Exporting to ONNX...")
    dummy_input = torch.randn(1, 83)
    
    torch.onnx.export(
        model, dummy_input, "attack_embedder.onnx",
        input_names=['features'],
        output_names=['embedding'],
        dynamic_axes={
            'features': {0: 'batch_size'},
            'embedding': {0: 'batch_size'}
        },
        opset_version=14,
        verbose=False
    )
    print("  ‚úÖ Exported: attack_embedder.onnx\n")
    
    print("Step 3: Verifying model...")
    onnx_model = onnx.load("attack_embedder.onnx")
    onnx.checker.check_model(onnx_model)
    print("  ‚úÖ Model verified\n")
    
    print("Model Information:")
    print("  Input:  features (batch, 83)")
    print("  Output: embedding (batch, 256)")
    print("  Type:   Attack-specific embedder")
    print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë  Attack Embedder Created ‚úÖ            ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")

if __name__ == "__main__":
    main()
```

---

## ‚úÖ CRITERIOS DE √âXITO D√çA 33

```
1. Chronos Embedder:
   ‚úÖ create_chronos_embedder.py created
   ‚úÖ chronos_embedder.onnx generated
   ‚úÖ Input: (batch, 83), Output: (batch, 512)
   ‚úÖ Model verified with onnx.checker
   
2. SBERT Embedder:
   ‚úÖ create_sbert_embedder.py created
   ‚úÖ sbert_embedder.onnx generated
   ‚úÖ Input: (batch, 83), Output: (batch, 384)
   ‚úÖ Model verified
   
3. Attack Embedder:
   ‚úÖ create_attack_embedder.py created
   ‚úÖ attack_embedder.onnx generated
   ‚úÖ Input: (batch, 83), Output: (batch, 256)
   ‚úÖ Model verified

4. .gitignore:
   ‚úÖ *.onnx ya est√° (Day 32)
   ‚úÖ Scripts en git, modelos no

5. Documentation:
   ‚úÖ README.md en /rag/models/ explicando modelos
```

---

## üìÖ TIMELINE - SEMANA 5 (ACTUALIZADO)

```
‚úÖ Day 31: FAISS + Anti-curse design
‚úÖ Day 32: ONNX Runtime test

üî• Day 33: Real embedders (4-6h) ‚Üê ESTAMOS AQU√ç
   - Chronos embedder (83‚Üí512-d)
   - SBERT embedder (83‚Üí384-d)
   - Attack embedder (83‚Üí256-d)
   - ONNX export + verification
   ‚ùå NO necesita FAISS design doc

üìÖ Day 34: Test embedders con datos reales (2-3h)
   - Cargar eventos JSONL
   - Extraer 83 features
   - Run inference
   - Verificar outputs
   ‚ùå NO necesita FAISS design doc

üìÖ Day 35: DimensionalityReducer (6h)
   ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md ‚Üê IMPORTANTE
   - Implement faiss::PCAMatrix
   - Train PCA (cuando tengamos 10K eventos)
   - Test reduction pipeline

üìÖ Day 36-38: Integration (8h)
   ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md ‚Üê IMPORTANTE
   - AttackIndexManager
   - SelectiveEmbedder
   - ChunkCoordinator
   - End-to-end tests
```

---

## üöÄ COMANDOS R√ÅPIDOS D√çA 33

```bash
# Crear directorio modelos
mkdir -p /vagrant/rag/models
cd /vagrant/rag/models

# Fase 1: Chronos (2h)
# [Crear create_chronos_embedder.py]
python3 create_chronos_embedder.py
ls -lh chronos_embedder.onnx

# Fase 2: SBERT (1.5h)
# [Crear create_sbert_embedder.py]
python3 create_sbert_embedder.py
ls -lh sbert_embedder.onnx

# Fase 3: Attack (1h)
# [Crear create_attack_embedder.py]
python3 create_attack_embedder.py
ls -lh attack_embedder.onnx

# Verificar todos
ls -lh *.onnx

# Git (scripts s√≠, modelos no)
cd /vagrant
git add rag/models/create_*.py
git add rag/models/README.md  # Si creamos
# NO: git add rag/models/*.onnx (gitignored)
```

---

## üèõÔ∏è VIA APPIA QUALITY - FILOSOF√çA DAY 33

> "No tenemos modelos custom entrenados. Podr√≠amos pasar 2 semanas
> entrenando, o podemos crear arquitecturas sint√©ticas AHORA para
> validar el pipeline. Elegimos lo segundo: modelos base que tienen
> la estructura correcta (83‚Üí512/384/256) para probar ingestion,
> PCA, √≠ndices separados. Los modelos reales son 'future work'. El
> pipeline es lo que importa ahora. Despacio, pero avanzando. üèõÔ∏è"

**Key Principle:**
- ‚úÖ Pipeline validation > Model perfection
- ‚úÖ Arquitectura correcta > Pesos entrenados
- ‚úÖ Progress incremental > Todo perfect

---

**Next**: Day 33 - Crear 3 embedders ONNX ‚Üí Day 34 - Test con datos reales ‚Üí Day 35 - DimensionalityReducer (**+ PASAR DESIGN DOC**)

**Via Appia Quality**: Modelos sint√©ticos para validar pipeline. Modelos reales = future work. Despacio y bien. üèõÔ∏è

---

## ‚úÖ Cambios en el Prompt Actualizado

**A√±adido:**
1. **Secci√≥n nueva al inicio**: "üìö DOCUMENTOS NECESARIOS PARA ESTA SESI√ìN"
2. **Recordatorio visual** con box para d√≠as futuros
3. **Explicaci√≥n clara** de cu√°ndo S√ç y cu√°ndo NO
4. **Timeline actualizado** con indicadores de cu√°ndo pasar doc

**Formato del recordatorio:**
```
Day 35 (DimensionalityReducer):
  ‚úÖ PASAR FAISS_ANTI_CURSE_DESIGN.md
  Raz√≥n: Implementar Estrategia #2 (PCA)
```

