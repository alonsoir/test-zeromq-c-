# Future Enhancements - Post Integration (Days 35+)

## ğŸ¯ TIMING: DespuÃ©s de Crypto Integration Complete

**NO TOCAR AHORA** - En medio de integraciones crÃ­ticas:
- DÃ­a 27: ml-detector + sniffer crypto-transport
- DÃ­a 28: Model Authority bÃ¡sico
- DÃ­a 29-30: RAG-Master naive

**IMPLEMENTAR DESPUÃ‰S** - Cuando pipeline estable (DÃ­a 35+)

---

## 1. Shadow Authority (ChatGPT-5 Enhancement)

### Concepto
```
Authoritative Model â†’ DECIDE (bloquea/permite)
Shadow Models â†’ OBSERVE (logean, no bloquean)
```

### Casos de Uso
- A/B testing natural en producciÃ³n
- Detectar ataques legacy (tÃ©cnicas 2020)
- Regression detection antes de deploy
- Mantener modelos antiguos sin riesgo

### Protobuf Changes (DÃ­a 35)
```protobuf
message ModelScore {
    string model_name = 1;
    float score = 2;
    bool shadow_mode = 3;  // â† AÃ‘ADIR
}

repeated string shadow_models = 91;  // â† AÃ‘ADIR
```

### ImplementaciÃ³n ml-detector
```cpp
// Config: models con mode="shadow"
if (model.mode == "shadow") {
    detect_and_log(event);  // Solo observa
    return;  // NO envÃ­a a firewall
}
```

### AnÃ¡lisis
```python
# Comparar authoritative vs shadow
shadow_unique = df[df['shadow_models'].str.contains('ddos_v1')]
auth_only = df[df['authoritative_model'] == 'ddos_v2']

# Â¿QuÃ© detecta v1 que v2 no?
regression_candidates = shadow_unique[~shadow_unique.isin(auth_only)]
```

---

## 2. Decision Outcome (Ground Truth)

### Concepto
```
Campo: decision_outcome
Valores: blocked, allowed, false_positive, false_negative, unknown, shadow
```

### Pipeline
```
T+0:     DetecciÃ³n â†’ "unknown"
T+1ms:   Firewall â†’ "blocked" o "allowed"
T+1day:  Review â†’ "false_positive" o "false_negative"
```

### Protobuf Changes (DÃ­a 40)
```protobuf
string decision_outcome = 90;  // â† AÃ‘ADIR
// "blocked", "allowed", "false_positive", "false_negative", "unknown", "shadow"
```

### Reentrenamiento
```python
# Ground truth validado
fps = df[df['decision_outcome'] == 'false_positive']  # â†’ benign
fns = df[df['decision_outcome'] == 'false_negative']  # â†’ malicious

# Reentrenar con errores corregidos
retrain_dataset = pd.concat([fps, fns])
```

---

## 3. Model Authority Enhancement (DÃ­a 28 - BÃ¡sico)

### Protobuf Changes (SIN romper)
```protobuf
// AÃ±adir a PacketEvent (campos 84-89)
string authoritative_model = 84;
float confidence = 85;
string decision_reason = 86;
float runner_up_score = 87;
string runner_up_source = 88;
repeated ModelScore model_scores = 89;
```

### ImplementaciÃ³n ml-detector
```cpp
// Identificar mejor modelo
event.set_authoritative_model("ddos_v2");
event.set_confidence(0.89);
event.set_decision_reason("ml won: 0.89 > 0.42");

// Individual scores
for (auto& [model, score] : all_scores) {
    auto* ms = event.add_model_scores();
    ms->set_model_name(model);
    ms->set_score(score);
}
```

---

## ğŸ¯ ROADMAP DE IMPLEMENTACIÃ“N
```
âœ… DÃ­a 27-28: Crypto Integration (PRIORIDAD)
   - ml-detector crypto-transport
   - sniffer crypto-transport
   - Stress test

âœ… DÃ­a 28: Model Authority BÃ¡sico (5 campos, SIN shadow)
   - Protobuf: campos 84-89
   - ml-detector: enrichment
   - Regenerar proto una sola vez
   - Tests validaciÃ³n

â³ DÃ­a 35: Shadow Authority (despuÃ©s de estabilizar)
   - Protobuf: campo 91 + ModelScore.shadow_mode
   - ml-detector: shadow mode execution
   - Config: model modes
   - AnÃ¡lisis comparativo

â³ DÃ­a 40: Decision Outcome (despuÃ©s de Shadow)
   - Protobuf: campo 90
   - Feedback loop firewall â†’ ml-detector
   - Manual review interface
   - Reentrenamiento pipeline
```

---

## ğŸ’¡ POR QUÃ‰ ESTE ORDEN

**DÃ­a 27-28: Crypto (CRÃTICO)**
- Bloquea todo desarrollo si no funciona
- Componentes deben comunicarse cifrados
- Base para producciÃ³n

**DÃ­a 28: Authority BÃ¡sico (FUNDACIONAL)**
- Habilita anÃ¡lisis cientÃ­fico
- No requiere cambios grandes
- Una regeneraciÃ³n proto controlada

**DÃ­a 35: Shadow (EXPERIMENTAL)**
- Requiere pipeline estable
- No crÃ­tico para paper
- Mejora incremental

**DÃ­a 40: Outcome (CIENCIA)**
- Requiere Shadow funcionando
- Ground truth para reentrenamiento
- Closed-loop learning

---

## ğŸ” DISCIPLINA DE CAMBIOS PROTOBUF

**Regla de Oro:**
> "Cambiar protobuf = recompilar TODO. Hacerlo una sola vez por milestone."

**Milestones Protobuf:**
1. âœ… DÃ­a 28: Model Authority (campos 84-89) â† UNA REGENERACIÃ“N
2. â³ DÃ­a 35: Shadow Authority (campo 91) â† UNA REGENERACIÃ“N
3. â³ DÃ­a 40: Decision Outcome (campo 90) â† UNA REGENERACIÃ“N

**NUNCA:**
- Cambios protobuf mid-integration
- MÃºltiples regeneraciones en un dÃ­a
- Sin testing completo despuÃ©s

---

## ğŸ“Š VALOR CIENTÃFICO (Papers)

**Paper 1: Dual-Score Architecture**
- DÃ­a 28: authoritative_model data âœ…
- DÃ­a 35: shadow models comparison

**Paper 2: Distributed Observatory**
- DÃ­a 29-30: RAG-Master foundation
- Semana 5: Cross-site analysis

**Paper 3: Closed-Loop Learning**
- DÃ­a 40: decision_outcome
- Semana 6: Retraining pipeline
- Semana 7: LLM fine-tuning

---

## âœ… CONCLUSIÃ“N

**ChatGPT-5 tiene razÃ³n en CONCEPTO.**
**Alonso tiene razÃ³n en TIMING.**

Documentar ahora = value capture sin riesgo
Implementar despuÃ©s = disciplina de ingenierÃ­a

Via Appia Quality: Plan â†’ Execute â†’ Validate

No volverse loco. Despacio pero bien. ğŸ›ï¸