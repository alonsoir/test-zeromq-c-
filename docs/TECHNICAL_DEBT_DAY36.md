# TECHNICAL DEBT - Day 36 Discovery
**Date:** 09-Enero-2026  
**Discovered During:** Day 36 PCA Training Pipeline Planning  
**Severity:** ğŸŸ¡ MEDIUM - System functional but RAG/FAISS pipeline incomplete  
**Impact:** FAISS ingestion pipeline blocked until resolved

---

## Executive Summary

Durante la planificaciÃ³n de Day 36 (training pipeline PCA), descubrimos una **desconexiÃ³n arquitectural** entre los sistemas de extracciÃ³n de features y los embedders ONNX creados para FAISS. El sistema de detecciÃ³n en tiempo real funciona correctamente (20+ horas estables), pero los eventos guardados para RAG/FAISS no contienen las features necesarias para los embedders.

**Estado Actual:**
- âœ… Sistema de detecciÃ³n: FUNCIONAL
- âŒ Pipeline RAG/FAISS: INCOMPLETO
- ğŸ”„ SoluciÃ³n: Plan Aâ†’Bâ†’A' (3-4 dÃ­as)

---

## The Gap - Sistemas Desconectados

### Sistema 1: Feature Extraction Legacy (83 features) - NUNCA USADO

```
Componente: FeatureExtractor (sniffer/src/userspace/feature_extractor.cpp)
PropÃ³sito:  ExtracciÃ³n completa de 83 features para datasets CTU-13
Estado:     âœ… CÃ“DIGO EXISTE - âŒ NUNCA SE USA EN PRODUCCIÃ“N

Features extraÃ­das (83):
â”œâ”€ Original 23: duration, spkts, dpkts, sbytes, dbytes, sload, smean, dmean, 
â”‚               flow_iat_mean, flow_iat_std, fwd_psh_flags, bwd_psh_flags, 
â”‚               fwd_urg_flags, bwd_urg_flags, packet_len_mean, packet_len_std,
â”‚               packet_len_var, fin/syn/rst/psh/ack/urg_flag_count
â”œâ”€ Phase 1 (20): dload, rate, srate, drate, ratios, IAT max/min, 
â”‚                 packet lengths, headers, ECE/CWR flags
â”œâ”€ Phase 2 (15): forward/backward IAT stats, active/idle times, fwd_len_std
â”œâ”€ Phase 3 (20): subflow stats, bulk transfer, window sizes, headers
â””â”€ Phase 4 (5):  avg packet/segment sizes, bulk packets

Entrada:  FlowStatistics (con vectores completos de timestamps, lengths, etc.)
Salida:   std::array<double, 83>

Uso real: âŒ NUNCA llamado desde ring_consumer.cpp
```

**RazÃ³n de NO uso:** DiseÃ±ado para datasets offline. El pipeline en tiempo real usa otro sistema.

---

### Sistema 2: ML Defender Extractor (40 features) - EN USO PERO INCOMPLETO

```
Componente: MLDefenderExtractor (sniffer/src/userspace/ml_defender_features.cpp)
PropÃ³sito:  Features para 4 detectores C++20 embebidos (tiempo real)
Estado:     âœ… CÃ“DIGO EXISTE - âš ï¸ NO SE GUARDA EN .pb

Features extraÃ­das (40):
â”œâ”€ DDoS (10):        syn_ack_ratio, packet_symmetry, source_ip_dispersion, etc.
â”œâ”€ Ransomware (10):  io_intensity, entropy, resource_usage, network_activity, etc.
â”œâ”€ Traffic (10):     packet_rate, connection_rate, tcp_udp_ratio, avg_packet_size, etc.
â””â”€ Internal (10):    connection_rate, service_port_consistency, lateral_movement, etc.

Entrada:  FlowStatistics (mismo que FeatureExtractor)
Salida:   4 submensajes protobuf (DDoSFeatures, RansomwareEmbeddedFeatures, etc.)

CÃ³digo en ring_consumer.cpp lÃ­nea 693:
    ml_extractor_.populate_ml_defender_features(*flow_stats, proto_event);

Estado en .pb guardados:
    âŒ Submensajes VACÃOS (ddos_embedded, ransomware_embedded, etc.)
    âŒ Solo 11 campos bÃ¡sicos guardados
    âœ… Tag "requires_processing" presente (sabÃ­amos que faltaba algo)
```

---

### Sistema 3: Embedders ONNX (83 features) - PLACEHOLDER

```
Componente: chronos_embedder.onnx, sbert_embedder.onnx, attack_embedder.onnx
PropÃ³sito:  Generar embeddings para FAISS vector search
Estado:     âœ… MODELOS EXISTEN - âŒ NUNCA RECIBEN DATOS REALES

Arquitectura:
â”œâ”€ chronos_embedder.onnx:  83 features â†’ 512-d embedding
â”œâ”€ sbert_embedder.onnx:    83 features â†’ 384-d embedding
â””â”€ attack_embedder.onnx:   83 features â†’ 256-d embedding

CreaciÃ³n: PyTorch MLP sintÃ©ticos (create_*_embedder.py)
Training: Datos sintÃ©ticos (torch.randn(1, 83))
ValidaciÃ³n: Test C++ PASSED (Day 34)

Estado actual:
    âœ… ONNX models operacionales
    âœ… C++ inference funciona
    âŒ Esperan 83 features que NO existen en .pb guardados
    âŒ Gap: .pb tiene 11 campos, embedders esperan 83
```

---

## Root Cause Analysis

### Â¿Por quÃ© pasÃ³ esto?

**1. EvoluciÃ³n del proyecto en fases:**
```
Fase 1 (CTU-13):    FeatureExtractor (83) diseÃ±ado para datasets offline
Fase 2 (Tiempo Real): MLDefenderExtractor (40) para detecciÃ³n instantÃ¡nea
Fase 3 (FAISS/RAG):   Embedders ONNX (83) como placeholders para validar pipeline
```

**2. Sistemas paralelos nunca se conectaron:**
- FeatureExtractor (83) â† legacy, nunca integrado
- MLDefenderExtractor (40) â† funciona en tiempo real, no se guarda
- Embedders ONNX (83) â† creados para futuro, esperan features inexistentes

**3. Tag "requires_processing" dejado como recordatorio:**
```cpp
// ring_consumer.cpp lÃ­nea 678
proto_event.add_event_tags("requires_processing");
```
**SabÃ­amos** que faltaba procesamiento adicional, pero nunca se implementÃ³.

---

## Current State - What Works vs What Doesn't

### âœ… Sistema de DetecciÃ³n (FUNCIONA PERFECTAMENTE)

```
Pipeline en tiempo real:
    eBPF Sniffer â†’ 11 campos bÃ¡sicos â†’ ZeroMQ â†’ ml-detector
                                                    â†“
                                        FeatureExtractor (ml-detector)
                                                    â†“
                                        Extrae features de 11 campos:
                                        â”œâ”€ Level 1: 23 features â†’ ONNX
                                        â”œâ”€ Level 2: 10 features â†’ DDoS C++20
                                        â”œâ”€ Level 2: 10 features â†’ Ransomware C++20
                                        â”œâ”€ Level 3: 10 features â†’ Traffic C++20
                                        â””â”€ Level 3: 10 features â†’ Internal C++20
                                                    â†“
                                        Dual-Score Decision System
                                                    â†“
                                        Detection Output âœ…

Estado: 20+ horas de operaciÃ³n continua sin fallos
Performance: Detectando ataques correctamente
Problema: NINGUNO - Este sistema estÃ¡ completo
```

---

### âŒ Pipeline RAG/FAISS (INCOMPLETO)

```
Pipeline FAISS (planeado):
    Eventos histÃ³ricos â†’ .pb guardados (11 campos) âŒ
                              â†“
                      "requires_processing" tag
                              â†“
                      ??? PROCESADOR FALTANTE ???
                              â†“
                      83 features completas âŒ
                              â†“
                      ONNX Embedders (512/384/256-d) âŒ
                              â†“
                      PCA Reduction (128-d) âŒ
                              â†“
                      FAISS Index âŒ

Estado actual:
    .pb files: Solo 11 campos bÃ¡sicos de NetworkFeatures
    Esperado: 83 features o 40 features completas
    Gap: 72-79 features faltantes
    Bloqueado: Cannot train PCA without proper features
```

---

## Impact Assessment

### Sistema de DetecciÃ³n
**Impact:** âœ… NONE - System functional
- Detectores funcionan correctamente
- Performance dentro de expectativas
- Sin cambios necesarios

### Sistema RAG/FAISS
**Impact:** ğŸ”´ BLOCKING - Pipeline incomplete
- Cannot train PCA reducers with real data
- Cannot populate FAISS indices
- Cannot perform semantic search on historical events
- Day 36-40 blocked until resolved

### Timeline Impact
```
Original Plan:
    Day 36: Train PCA with real data (4-6h) âŒ BLOCKED
    Day 37-38: Integration testing
    Day 39-40: FAISS ingester implementation

With workaround (Plan Aâ†’Bâ†’A'):
    Day 36: Train PCA with synthetic data (4-6h) âœ… UNBLOCKED
    Day 37-38: Implement feature processing (2-3 days)
    Day 36 BIS: Re-train PCA with real data (2h)
    Day 39-40: Continue as planned
```

**Net delay:** 1-2 days (if Plan B takes 2 days instead of 3)

---

## Solution Strategy - Plan Aâ†’Bâ†’A'

### Plan A: Synthetic Data Workaround (Day 36 - 4-6h)

**Objective:** Validate pipeline end-to-end with synthetic data

```python
# Generate synthetic 83-feature events
synthetic_features = np.random.randn(20000, 83).astype(np.float32)

# Pass through ONNX embedders
chronos_emb = chronos_model(synthetic_features)  # 20K Ã— 512
sbert_emb = sbert_model(synthetic_features)      # 20K Ã— 384
attack_emb = attack_model(synthetic_features)    # 20K Ã— 256

# Train PCA reducers
pca_chronos.fit(chronos_emb)  # 512 â†’ 128, target â‰¥96% variance
pca_sbert.fit(sbert_emb)      # 384 â†’ 128, target â‰¥96% variance
pca_attack.fit(attack_emb)    # 256 â†’ 128, target â‰¥96% variance

# Save models
save_models("/shared/models/pca/")
```

**Deliverables:**
- âœ… 3 PCA models trained and saved
- âœ… Training pipeline code validated
- âœ… End-to-end architecture proven
- âœ… Documentation and tests written
- âš ï¸ Variance may be lower (synthetic data has no semantic structure)

**Advantages:**
- Unblocks Day 36-40 FAISS work
- Validates training code before real data
- Provides baseline for comparison
- Scientifically honest (we document it's synthetic)

**Via Appia Quality:** Foundation first, even if temporary

---

### Plan B: Implement Real Feature Processing (Day 37-38 - 2-3 days)

**Objective:** Get real 83 or 40 features into .pb files

#### Option B1: Activate MLDefenderExtractor (40 features) - RECOMMENDED

```
Status:  Code exists but output not saved to .pb
Effort:  ~1 day
Quality: â­â­â­â­â­ (uses proven extraction code)

Implementation:
1. Verify ml_extractor_.populate_ml_defender_features() is called
2. Debug why submessages are empty in .pb
3. Fix serialization issue
4. Validate .pb contains 4 submessages with 10 features each

Result: .pb files with 40 real features

Challenge: 40 â‰  83
Solutions:
  a) Retrain embedders for 40 features (3h)
  b) Pad/derive 83 features from 40 (engineering effort)
  c) Use 40 for now, add 83 later (incremental)
```

#### Option B2: Implement Full 83-Feature Processor

```
Status:  FeatureExtractor exists but not connected
Effort:  ~2-3 days
Quality: â­â­â­â­ (reuses existing extraction logic)

Implementation:
1. Create processor that reads .pb raw
2. Extract FlowStatistics from events
3. Call FeatureExtractor::extract_features(flow) â†’ 83 features
4. Save to new format or update .pb

Result: .pb files or separate files with 83 features

Challenge: FlowStatistics reconstruction
- .pb raw has 11 basic fields
- FeatureExtractor needs vectors (timestamps, lengths, etc.)
- May need to aggregate multiple packets into flows
```

#### Option B3: Extend Ring Consumer to Save Full Features

```
Status:  Requires changes to production sniffer
Effort:  ~2 days
Quality: â­â­â­ (cleaner but riskier)
Risk:    May impact production stability

Implementation:
1. Modify ring_consumer.cpp to call FeatureExtractor
2. Populate NetworkFeatures with all 83 fields
3. Ensure serialization works
4. Test thoroughly before deployment

Result: Future .pb files have 83 features

Challenge: Backward compatibility, testing burden
```

**RECOMMENDATION:** Start with Option B1 (40 features) as lowest risk, fastest path.

---

### Plan A': Re-train with Real Data (Day 36 BIS - 2h)

**Objective:** Validate real data pipeline using same training code

```python
# EXACT SAME CODE as Plan A, only data source changes:

# Load real features from processed .pb
real_features = load_from_processed_pb(
    "/vagrant/logs/rag/processed/*.pb",
    num_samples=20000,
    balanced=True
)  # Now shape (20000, 40) or (20000, 83)

# Rest is IDENTICAL to Plan A
chronos_emb = chronos_model(real_features)
pca_chronos.fit(chronos_emb)
# ... etc ...
```

**Deliverables:**
- âœ… 3 PCA models trained with REAL data
- âœ… Variance comparison: synthetic vs real
- âœ… Same code reused (validation of Plan A)
- âœ… Ready for production FAISS ingestion

**Scientific Value:**
- Documents evolution: synthetic â†’ real
- Shows variance improvement with real data
- Validates both pipeline stages independently

---

## Decision Matrix

| Option | Effort | Risk | Quality | Timeline | Recommendation |
|--------|--------|------|---------|----------|----------------|
| **Plan A (Synthetic)** | 4-6h | ğŸŸ¢ Low | â­â­â­ | Day 36 | âœ… DO THIS FIRST |
| **Plan B1 (40 feat)** | 1 day | ğŸŸ¢ Low | â­â­â­â­â­ | Day 37 | âœ… RECOMMENDED |
| **Plan B2 (83 proc)** | 2-3d | ğŸŸ¡ Medium | â­â­â­â­ | Day 37-38 | ğŸ”„ IF B1 INSUFFICIENT |
| **Plan B3 (Sniffer)** | 2d | ğŸ”´ High | â­â­â­ | Day 37-38 | âŒ AVOID (prod risk) |
| **Plan A' (Real)** | 2h | ğŸŸ¢ Low | â­â­â­â­â­ | After B | âœ… VALIDATION |

---

## Timeline with Solution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WEEK 5-6: FAISS INFRASTRUCTURE (Days 31-40)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 31-34: Infrastructure + ONNX validation      âœ… DONE    â”‚
â”‚ Day 35:    DimensionalityReducer library         âœ… DONE    â”‚
â”‚ Day 36:    Plan A - Train PCA (synthetic)        ğŸ”¥ NEXT    â”‚
â”‚ Day 37:    Plan B1 - Activate 40 features        ğŸ“… PLANNED â”‚
â”‚ Day 38:    Plan A' - Re-train PCA (real)         ğŸ“… PLANNED â”‚
â”‚ Day 39-40: Buffer / FAISS ingester start         ğŸ“… PLANNED â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Net Impact: 1 day delay (if B1 takes 1 day instead of planned buffer)
Result: Foundation validated twice (synthetic + real)
Quality: Via Appia - methodical, documented, reproducible
```

---

## Lessons Learned

### What Went Right âœ…
1. **Detection system:** Fully functional, no technical debt here
2. **Early discovery:** Found issue during planning, not during execution
3. **Code exists:** Both extractors written, just not connected
4. **Workaround viable:** Synthetic data validates architecture

### What Went Wrong âŒ
1. **Parallel development:** Two feature systems never integrated
2. **Incomplete testing:** Embedders validated with synthetic, never checked real data path
3. **Tag ignored:** "requires_processing" left as TODO without follow-up

### How to Prevent ğŸ›¡ï¸
1. **End-to-end validation:** Always test full pipeline with real data
2. **TODO tracking:** Every "requires_processing" needs a ticket
3. **Integration tests:** Don't just unit test components in isolation
4. **Documentation:** Architecture diagrams showing data flow

---

## Action Items

### Immediate (Day 36)
- [ ] Execute Plan A (synthetic PCA training)
- [ ] Document training pipeline code
- [ ] Validate architecture end-to-end
- [ ] Create Plan B implementation tickets

### Short-term (Day 37-38)
- [ ] Execute Plan B1 (activate 40 features)
- [ ] Debug why MLDefenderExtractor output not saved
- [ ] Validate .pb files contain submessages
- [ ] Execute Plan A' (re-train with real data)

### Medium-term (Week 6-7)
- [ ] Consider Plan B2 if 40 features insufficient
- [ ] Document feature extraction architecture
- [ ] Create integration tests for feature pipeline
- [ ] Remove "requires_processing" tag once complete

### Long-term (Phase 3+)
- [ ] Unify feature extraction (single source of truth)
- [ ] Evaluate if 83 features needed or 40 sufficient
- [ ] Consider feature engineering for better embeddings
- [ ] Performance optimization of feature extraction

---

## Communication

### Stakeholder Impact
**Alonso (Project Lead):**
- System functional, no production impact
- 1 day timeline slip (acceptable for quality)
- Foundation-first approach validated
- Scientific honesty maintained (document syntheticâ†’real)

**Future Developers:**
- Clear documentation of why two systems exist
- Path forward documented
- Workarounds explained with rationale

---

## References

### Code Locations
```
Feature Extraction Legacy (83):
â”œâ”€ /vagrant/sniffer/include/feature_extractor.hpp
â””â”€ /vagrant/sniffer/src/userspace/feature_extractor.cpp

ML Defender Extractor (40):
â”œâ”€ /vagrant/sniffer/include/ml_defender_features.hpp
â””â”€ /vagrant/sniffer/src/userspace/ml_defender_features.cpp

Ring Consumer Integration:
â””â”€ /vagrant/sniffer/src/userspace/ring_consumer.cpp (line 693)

ONNX Embedders:
â”œâ”€ /vagrant/rag/models/chronos_embedder.onnx
â”œâ”€ /vagrant/rag/models/sbert_embedder.onnx
â””â”€ /vagrant/rag/models/attack_embedder.onnx

Protobuf Schema:
â””â”€ /vagrant/protobuf/network_security.proto
```

### Related Documents
- `BACKLOG.md` - Updated with Plan Aâ†’Bâ†’A'
- `PROMPT_CONTINUE_CLAUDE.md` - Day 36 context
- `journal.txt` - Day 36 discovery log

---

## Conclusion

This is **NOT a critical bug** - it's an **incomplete feature** discovered during planning. The detection system works perfectly. The FAISS/RAG pipeline needs connection work.

**Via Appia Philosophy Applied:**
> "Better to build foundation twice (synthetic + real) than to rush and build poorly once."

**Plan Aâ†’Bâ†’A'** allows us to:
1. Validate architecture NOW (unblock progress)
2. Fix data pipeline PROPERLY (no hacks)
3. Re-validate with real data (scientific rigor)
4. Document journey (transparency)

**Timeline Impact:** Minimal (1 day)  
**Quality Impact:** Positive (double validation)  
**Risk Mitigation:** Excellent (incremental approach)

ğŸ›ï¸ **Via Appia Quality: Foundation First** ğŸ›ï¸

---

**Document Version:** 1.0  
**Author:** Claude (Anthropic) + Alonso  
**Date:** 09-Enero-2026  
**Status:** ğŸ“‹ DOCUMENTED - Ready for Day 36 execution  
**Next Review:** After Plan B completion