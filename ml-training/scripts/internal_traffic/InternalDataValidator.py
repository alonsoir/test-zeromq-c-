# ml-training-scripts/internal_traffic/InternalDataValidator.py
import json
import pandas as pd
from InternalFeatures import INTERNAL_FEATURES

class InternalDataValidator:
    def __init__(self, dataset_path: str):
        self.dataset_path = dataset_path

    def validate_separability(self):
        """Valida que las clases sean separables"""
        with open(self.dataset_path, 'r') as f:
            data = json.load(f)

        df = pd.DataFrame(data['dataset'])

        # AnÃ¡lisis de separaciÃ³n por feature
        separability_scores = {}
        for feature in INTERNAL_FEATURES:
            benign_mean = df[df['label'] == 'benign'][feature].mean()
            suspicious_mean = df[df['label'] == 'suspicious'][feature].mean()
            separation = abs(benign_mean - suspicious_mean) / df[feature].std()
            separability_scores[feature] = separation

        print("ğŸ“Š Separabilidad de features Internal Traffic:")
        for feature, score in sorted(separability_scores.items(), key=lambda x: x[1], reverse=True):
            print(f"  {feature}: {score:.3f}")

        return separability_scores

    def analyze_threat_patterns(self):
        """AnÃ¡lisis especÃ­fico de patrones de amenaza interna"""
        with open(self.dataset_path, 'r') as f:
            data = json.load(f)

        df = pd.DataFrame(data['dataset'])
        suspicious_data = df[df['label'] == 'suspicious']

        print("\nğŸ” AnÃ¡lisis de Patrones de Amenaza Interna:")

        # Lateral Movement patterns
        high_lateral = len(suspicious_data[suspicious_data['lateral_movement_score'] > 0.7])
        print(f"  Lateral Movement indicators: {high_lateral}/{len(suspicious_data)} muestras")

        # Service Discovery patterns
        high_discovery = len(suspicious_data[suspicious_data['service_discovery_patterns'] > 0.7])
        print(f"  Service Discovery indicators: {high_discovery}/{len(suspicious_data)} muestras")

        # Data Exfiltration patterns
        high_exfiltration = len(suspicious_data[suspicious_data['data_exfiltration_indicators'] > 0.7])
        print(f"  Data Exfiltration indicators: {high_exfiltration}/{len(suspicious_data)} muestras")

        # Temporal Anomalies
        high_temporal = len(suspicious_data[suspicious_data['temporal_anomaly_score'] > 0.7])
        print(f"  Temporal Anomalies indicators: {high_temporal}/{len(suspicious_data)} muestras")

# AÃ‘ADIR ESTO PARA EJECUCIÃ“N
if __name__ == "__main__":
    validator = InternalDataValidator("internal_traffic_dataset.json")
    separability_scores = validator.validate_separability()

    # AnÃ¡lisis adicional
    print(f"\nğŸ¯ Resumen de separabilidad Internal Traffic:")
    max_score = max(separability_scores.values())
    min_score = min(separability_scores.values())
    avg_score = sum(separability_scores.values()) / len(separability_scores)

    print(f"  MÃ¡xima separaciÃ³n: {max_score:.3f}")
    print(f"  MÃ­nima separaciÃ³n: {min_score:.3f}")
    print(f"  Promedio: {avg_score:.3f}")

    # EvaluaciÃ³n cualitativa
    if avg_score > 1.5:
        print("âœ… Excelente separaciÃ³n - Datos de alta calidad para Internal Traffic")
    elif avg_score > 1.0:
        print("âœ… Buena separaciÃ³n - Datos adecuados para entrenamiento")
    else:
        print("âš ï¸  SeparaciÃ³n moderada - Considerar ajustar features")

    # AnÃ¡lisis de patrones especÃ­ficos
    validator.analyze_threat_patterns()