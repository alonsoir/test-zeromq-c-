{
  "model_path": "../models/tinyllama-1.1b-chat-v1.0.Q4_0.gguf",
  "security_level": 3,
  "use_llm": true,
  "etcd_endpoint": "http://localhost:2379",
  "whitelist_path": "../config/command_whitelist.json",
  "log_level": "info",
  "llama_config": {
    "context_size": 2048,
    "batch_size": 512,
    "gpu_layers": 0,
    "use_mlock": false,
    "use_mmap": true
  }
}